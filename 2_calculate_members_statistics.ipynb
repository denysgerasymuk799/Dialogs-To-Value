{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import gender_guesser.detector as gender\n",
    "from config import PATH_TO_DIALOGS_META, PATH_TO_SAVE_PROCESSED_FILES, PATH_TO_SAVE_GENERAL_DF, \\\n",
    "    USER_PATH_TO_SAVE_GENERAL_DF\n",
    "\n",
    "from utils.text_data_transformation import transform_raw_data\n",
    "from utils.dialog_manipulation import detect_data_language, \\\n",
    "    get_user_step_msgs, if_name_in_dict, add_sleep_bounds, add_subdialogs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set up\n",
    "\n",
    "# pd.set_option('display.max_rows', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the path\n",
    "\n",
    "if not os.path.isfile(PATH_TO_SAVE_GENERAL_DF):\n",
    "    logging.error(f'No Dataframe associated with {PATH_TO_SAVE_GENERAL_DF}')\n",
    "else:\n",
    "    df = pd.read_csv(PATH_TO_SAVE_GENERAL_DF)\n",
    "    # df = df.rename(columns={'dialog ID': 'dialog_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "def add_sleep_data(data: pd.DataFrame, user_df_path, save=True):\n",
    "    \"\"\"\n",
    "    Add sleep data for each message in a dialog,\n",
    "    and add it in a new column for a particular user,\n",
    "    return new dataframe\n",
    "    \"\"\"\n",
    "    gdf = pd.DataFrame(add_sleep_bounds(data))\n",
    "    if save:\n",
    "        gdf.to_csv(user_df_path, index=False)\n",
    "\n",
    "def add_stats_data(data: pd.DataFrame, df_path, save=True):\n",
    "    \"\"\"\n",
    "    Add mean data for each subdialogs in a dialog,\n",
    "    and add it in a new column for a particular stats,\n",
    "    return new dataframe\n",
    "    \"\"\"\n",
    "    adf = add_subdialogs_stats(data)\n",
    "    data['words_num_mean'] = adf['words_num_mean']\n",
    "    data['reply_time_mean'] = adf['reply_time_mean']\n",
    "    data['message_number_mean'] = adf['message_number_mean']\n",
    "    if save:\n",
    "        data.to_csv(df_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Aggregating data\n",
    "add_stats_data(df, PATH_TO_SAVE_GENERAL_DF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\my_work\\programming\\telegram-dialogs-analysis\\utils\\dialog_manipulation.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sleep_end'] = data.apply(lambda x: datetime.datetime.strptime(x[\"date\"][:19], time_format).hour, axis=1)\n",
      "D:\\my_work\\programming\\telegram-dialogs-analysis\\utils\\dialog_manipulation.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sleep_start'] = data.apply(lambda x: (datetime.datetime.strptime(x[\"date\"][:19], time_format) - datetime.timedelta(seconds=x['reply_btw_sender_time'])).hour, axis=1)\n",
      "d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# User stats\n",
    "add_sleep_data(df, USER_PATH_TO_SAVE_GENERAL_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_user_gender(username, name_dicts):\n",
    "    user_gender = ''\n",
    "\n",
    "    first_name = username.strip().split()[0].lower()\n",
    "    print('first_name', first_name)\n",
    "\n",
    "    new_df = pd.DataFrame({'message': [first_name]})\n",
    "    word_lang = detect_data_language(new_df, 'one_word')\n",
    "\n",
    "    for num_df, names_df in enumerate(name_dicts[word_lang]):\n",
    "        if not names_df.loc[names_df['name'].str.lower() == first_name].empty or\\\n",
    "                if_name_in_dict(first_name, names_df):\n",
    "            if num_df == 0:\n",
    "                user_gender = 'female'\n",
    "            else:\n",
    "                user_gender = 'male'\n",
    "            print(f\"{first_name} gender is {user_gender}\\n\")\n",
    "            break\n",
    "\n",
    "    if user_gender == '' and word_lang == 'en':\n",
    "        gender_detector = gender.Detector()\n",
    "        user_gender = gender_detector.get_gender(first_name.capitalize())\n",
    "        if user_gender == 'unknown':\n",
    "            user_gender = ''\n",
    "        print(f\"{first_name} gender is {user_gender}\\n\")\n",
    "\n",
    "    return user_gender\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def get_gender_by_verb(user_id, dialog_id, user_general_df):\n",
    "    lang = detect_data_language('', 'df_loc', PATH_TO_SAVE_GENERAL_DF, dialog_id, user_id)\n",
    "\n",
    "    user_gender = ''\n",
    "    if lang == 'en':\n",
    "        return user_gender\n",
    "\n",
    "    female_gender, male_gender = 0, 0\n",
    "    dialog_step_msgs = get_user_step_msgs(PATH_TO_SAVE_GENERAL_DF, dialog_id, user_id, 100, user_general_df)\n",
    "\n",
    "    for msg in dialog_step_msgs:\n",
    "        msg = transform_raw_data(msg, lang, '', '', 'without_lemma')\n",
    "        for word in msg.split():\n",
    "            word = word.strip()\n",
    "            print(word)\n",
    "            if len(word) <= 2:\n",
    "                continue\n",
    "\n",
    "            if lang == 'ua':\n",
    "                if word[-2:] == 'Ð»Ð°' and morph.tag(word)[0].POS in ('VERB', 'GRND'):\n",
    "                    print('ukr word', word)\n",
    "                    female_gender += 1\n",
    "\n",
    "                elif word[-1] in ('Ð²','Ðº','Ñ')  and morph.tag(word)[0].POS in ('VERB', 'GRND'):\n",
    "                    print('ukr word', word)\n",
    "                    male_gender += 1\n",
    "\n",
    "            elif lang == 'ru':\n",
    "                segmenter = Segmenter()\n",
    "                doc = Doc(word)\n",
    "                emb = NewsEmbedding()\n",
    "                morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "                doc.segment(segmenter)\n",
    "                doc.tag_morph(morph_tagger)\n",
    "\n",
    "                if word[-2:] == 'Ð»Ð°' and doc.tokens[0].pos in ('VERB', 'AUX'):\n",
    "                    print('ru word', word)\n",
    "                    female_gender += 1\n",
    "\n",
    "\n",
    "                elif word[-1] in ('Ð»','Ðº','Ñ') and doc.tokens[0].pos in ('VERB', 'AUX'):\n",
    "                    print('ru word', word)\n",
    "                    male_gender += 1\n",
    "\n",
    "    if male_gender > female_gender:\n",
    "        user_gender = 'male'\n",
    "\n",
    "    elif male_gender < female_gender:\n",
    "        user_gender = 'female'\n",
    "\n",
    "    else:\n",
    "        user_gender = ''\n",
    "\n",
    "    return user_gender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pymorphy2-dicts-uk in d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages (2.4.1.1.1460299261)\n",
      "Requirement already up-to-date: pymorphy2-dicts-ru in d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages (2.4.404381.4453942)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pymorphy2-dicts-uk\n",
    "!pip install -U pymorphy2-dicts-ru"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "female_ukr_names = pd.read_csv(os.path.join('dicts', 'female_ukrainian_names.csv'))\n",
    "male_ukr_names = pd.read_csv(os.path.join('dicts', 'male_ukrainian_names.csv'))\n",
    "female_ru_names = pd.read_csv(os.path.join('dicts', 'female_russian_names.csv'))\n",
    "male_ru_names = pd.read_csv(os.path.join('dicts', 'male_russian_names.csv'))\n",
    "\n",
    "female_ru_ukr_trans_names = pd.read_csv(os.path.join('dicts', 'female_ru_ukr_trans_names.csv'))\n",
    "male_ru_ukr_trans_names = pd.read_csv(os.path.join('dicts', 'male_ru_ukr_trans_names.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "members_statistics_df = pd.read_csv(USER_PATH_TO_SAVE_GENERAL_DF)\n",
    "\n",
    "members_statistics_df['first_name'], members_statistics_df['last_name'],\\\n",
    "members_statistics_df['username'], members_statistics_df['gender'] = '', '', '', ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============1 users from 297 succeeded\n",
      "first_name ivan\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "ivan gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============2 users from 297 succeeded\n",
      "first_name yurii\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "yurii gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============3 users from 297 succeeded\n",
      "first_name vitaliia\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "vitaliia gender is \n",
      "\n",
      "first_name ioffe\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "ioffe gender is \n",
      "\n",
      "Ð²Ð¾Ð¾Ð±Ñ‰Ðµ\n",
      "Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹\n",
      "ÑÐµÐ¹Ð»Ð·\n",
      "Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============4 users from 297 succeeded\n",
      "first_name azim\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "azim gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============5 users from 297 succeeded\n",
      "first_name max.d\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "max.d gender is \n",
      "\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============6 users from 297 succeeded\n",
      "first_name quartermaster\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "quartermaster gender is \n",
      "\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============7 users from 297 succeeded\n",
      "first_name sawyer\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "sawyer gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============8 users from 297 succeeded\n",
      "first_name eugene\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "eugene gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============9 users from 297 succeeded\n",
      "first_name hex\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "hex gender is \n",
      "\n",
      "Ð½Ð°ÑˆÐ»Ð¸ÑÑŒ\n",
      "ÐºÐ½Ð¸Ð¶ÐºÐ¸\n",
      "Ð¸Ñ‰Ñƒ\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============10 users from 297 succeeded\n",
      "first_name eugene\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "eugene gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============11 users from 297 succeeded\n",
      "first_name maria\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "maria gender is female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============12 users from 297 succeeded\n",
      "first_name stas\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "stas gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============13 users from 297 succeeded\n",
      "first_name serhey\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "serhey gender is \n",
      "\n",
      "first_name shmyg\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "shmyg gender is \n",
      "\n",
      "Ð´ÑÐºÑƒÑŽ\n",
      "Ð´ÑÐºÑƒÑŽ\n",
      "Ð¿Ð¾Ð´Ð¸Ð²Ð»ÑŽÑÑŒ\n",
      "Ð²Ð¸Ñ‰Ðµ\n",
      "Ð·Ð³Ð°Ð´Ð°Ð½Ñ–\n",
      "Ð´ÑƒÐ¼Ð°ÑŽ\n",
      "Ñ‰Ð¾ÑÑŒ\n",
      "Ð¿Ñ–Ð´Ð±ÐµÑ€Ñƒ\n",
      "Ð¿Ð¾Ñ€Ð°Ð´Ð¸Ñˆ\n",
      "imrajdee\n",
      "Ð·ÑƒÑÑ‚Ñ€Ñ–Ñ‡Ð°Ð²\n",
      "ukr word Ð·ÑƒÑÑ‚Ñ€Ñ–Ñ‡Ð°Ð²\n",
      "ÑÑ‚Ð°Ñ‚Ñ‚ÑÑ…\n",
      "Ñ€Ñ–Ð·Ð½Ñ–\n",
      "Ð´ÑƒÐ¼Ð°Ð²\n",
      "ukr word Ð´ÑƒÐ¼Ð°Ð²\n",
      "Ñ‡Ð¾Ð³Ð¾\n",
      "Ð¾Ð±Ñ€Ð°Ñ‚Ð¸\n",
      "Ð¿Ñ€Ð¸Ð²Ñ–Ñ‚\n",
      "ÑÐºÐ¸Ð¹\n",
      "Ñ€Ð°Ð·Ñ–\n",
      "wysiwyg\n",
      "Ñ€ÐµÐ°ÐºÑ‚Ð°\n",
      "Ñ‚Ð¾Ð¿Ñ–\n",
      "Ñ€Ð¾Ð·Ñ–Ð±Ñ€Ð°Ñ‚Ð¸ÑÑŒ\n",
      "Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾Ñ‚\n",
      "ÐºÐ¾ÑÑ‚Ð¸Ð»ÑÑ‚Ð¸\n",
      "Ð¿Ð¾ÐºÐ°Ð¶Ð¸\n",
      "Ñ‚ÐµÐ¿ÐµÑ€\n",
      "Ð²Ð¸Ð³Ð»ÑÐ´Ð°Ñ”\n",
      "Ñ…Ñ‚Ð¾ÑÑŒ\n",
      "Ð·Ð°Ñ…Ð¾Ñ‡Ðµ\n",
      "Ð¿Ð¾Ñ€Ð°Ñ…ÑƒÐ²Ð°Ñ‚Ð¸\n",
      "Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ñƒ\n",
      "ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ\n",
      "Ð¼ÐµÐºÐ´Ð¶Ñ–Ð²\n",
      "ukr word Ð¼ÐµÐºÐ´Ð¶Ñ–Ð²\n",
      "Ð¿Ñ€Ð¸Ñ”Ð¼Ð½Ð¾\n",
      "Ð²Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹\n",
      "Ñ‡Ð¾Ð¼Ñƒ\n",
      "Ð¼ÐµÑÐµÐ´Ð¶Ñ–\n",
      "Ð²Ñ–Ð´Ñ€Ñ–Ð·Ð°Ñ‚Ð¸\n",
      "ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–\n",
      "Ð²ÑÑ–\n",
      "Ð¿ÑƒÑˆÑ–\n",
      "Ð¿Ñ–ÑÐ»Ñ\n",
      "ÑÐ»Ð°Ð¹ÑÑƒ\n",
      "Ð²Ñ–Ð´Ñ€Ñ–Ð¶\n",
      "Ð¿ÐµÑ€ÐµÐ½Ð°Ð·Ð½Ð°Ñ‡\n",
      "Ð¼ÐµÑÐµÐ´Ð¶Ñ–\n",
      "newstate\n",
      "messages\n",
      "state\n",
      "messages\n",
      "slice\n",
      "ÑÐºÐ¾Ð¿Ñ–ÑŽÐ²Ð°Ð²\n",
      "ukr word ÑÐºÐ¾Ð¿Ñ–ÑŽÐ²Ð°Ð²\n",
      "ÑÑ‚ÐµÐ¹Ñ‚\n",
      "Ð¼ÐµÑÐµÐ´Ð¶Ñ–\n",
      "Ð»Ñ–Ð½ÐºÑƒ\n",
      "Ð¿ÐµÑ€ÐµÐ´Ð°ÑŽÑ‚ÑŒÑÑ\n",
      "ÐºÐ¾Ð¿Ñ–ÑŽÐ¹\n",
      "ÑÑ‚ÐµÐ¹Ñ‚\n",
      "Ð³Ð»Ð¸Ð±Ð¾ÐºÐ¾\n",
      "ÑˆÐµÐ»Ð¾Ñƒ\n",
      "ÐºÐ¾Ð¿Ñ–\n",
      "ÑÐºÑ‰Ð¾\n",
      "Ð´Ð°Ð½Ñ–\n",
      "Ð´ÐµÑÑŒ\n",
      "Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸\n",
      "Ð°Ð¿Ñ†Ñ–\n",
      "Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´\n",
      "Ñ€Ñ–Ð·Ð½Ð¸Ñ…\n",
      "Ñ‡Ð°ÑÑ‚Ð¸Ð½Ñ…Ð°Ð¹\n",
      "Ð»ÐµÐ¹Ð°ÑƒÑ‚Ð°\n",
      "Ñ…ÐµÐ´ÐµÑ€Ñ–\n",
      "Ñ„ÑƒÑ‚ÐµÑ€Ñ–\n",
      "Ñ–Ð½ÑˆÑ–Ð¹\n",
      "ÑÑ‚Ð¾Ñ€Ñ–Ð½Ñ†Ñ–\n",
      "Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð¾Ð¼\n",
      "Ð¼Ð¾Ð¶Ðµ\n",
      "Ð´Ð°Ð½Ñ–\n",
      "ÑÐµÑÑ–Ñ—\n",
      "Ñ‚Ð¸Ð¿Ñƒ\n",
      "Ñ‚Ð¾ÐºÐµÐ½\n",
      "Ñ‰Ð¾ÑÑŒ\n",
      "Final gender is male\n",
      "\n",
      "\n",
      "\n",
      "============14 users from 297 succeeded\n",
      "first_name larisa\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "larisa gender is female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============15 users from 297 succeeded\n",
      "first_name pyroblaster\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "pyroblaster gender is \n",
      "\n",
      "quartermaster\n",
      "ÐºÑ€ÑƒÑ‚Ð°Ñ\n",
      "Ð°Ð²Ð°\n",
      "Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹\n",
      "Ð¾Ñ‰ÑƒÐ¿ÑŒ\n",
      "Ð³Ð°Ñ€ÑÑ‡ÐµÐµ\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============16 users from 297 succeeded\n",
      "first_name anastasia\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "anastasia gender is female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============17 users from 297 succeeded\n",
      "\n",
      "\n",
      "\n",
      "============18 users from 297 succeeded\n",
      "first_name sergei\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "sergei gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============19 users from 297 succeeded\n",
      "first_name alice\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "alice gender is female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============20 users from 297 succeeded\n",
      "first_name Ð´Ñ–Ð¼Ð°\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "Ð´Ñ–Ð¼Ð° gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============21 users from 297 succeeded\n",
      "first_name ðŸŒ³\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "first_name Ð¼ÑƒÐ»ÑŒÐºÐ¾\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "Ð²Ñ–Ñ‡Ð½Ð°Ñ\n",
      "Ð¿Ð°Ð¼ÑÑ‚ÑŒ\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============22 users from 297 succeeded\n",
      "first_name zumso\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "zumso gender is \n",
      "\n",
      "Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹\n",
      "ÐºÐ½Ð¸Ð³Ñƒ\n",
      "Ñ‡Ð¸Ñ‚Ð°ÑŽ\n",
      "Ð¼ÑƒÑ‡Ð°ÑŽÑÑŒ\n",
      "Ñ…Ð¾Ñ‡Ñƒ\n",
      "Ð¾Ñ‚Ð²Ð»ÐµÑ‡ÑŒÑÑ\n",
      "Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾\n",
      "Ð»ÐµÐ³ÐºÐ¸Ñ…\n",
      "ÐºÐ°ÑÐ°Ð½Ð¸Ð¹\n",
      "Ñ‡Ð¸Ñ‚Ð°Ð»\n",
      "ru word Ñ‡Ð¸Ñ‚Ð°Ð»\n",
      "Ð¸Ð½Ñ‚Ñ€Ð¸Ð³ÑƒÑŽÑ‰Ð¸Ðµ\n",
      "Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ\n",
      "Ð¿Ð¾Ð½ÑÐ»\n",
      "ru word Ð¿Ð¾Ð½ÑÐ»\n",
      "Ð´Ð°Ð½Ð½Ñ‹Ð¹\n",
      "Ð¼Ð¾Ð¼ÐµÐ½Ñ‚\n",
      "ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹\n",
      "Ð¿Ñ€Ð¾Ð·Ñ‹\n",
      "Ð¼Ð¾Ð¶ÐµÑ‚Ðµ\n",
      "ÐºÐ½Ð¸Ð³Ñƒ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\my_work\\programming\\telegram-dialogs-analysis\\utils\\dialog_manipulation.py:274: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  if n_row % msgs_step == 0:\n",
      "d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-9595df2336ac>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m                         \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m                     \u001B[0muser_gender\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_gender_by_verb\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'user_id'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdialog_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muser_general_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m                     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Final gender is {user_gender}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-8-ad32e9da6973>\u001B[0m in \u001B[0;36mget_gender_by_verb\u001B[1;34m(user_id, dialog_id, user_general_df)\u001B[0m\n\u001B[0;32m     41\u001B[0m                 \u001B[0mdoc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDoc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m                 \u001B[0memb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNewsEmbedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m                 \u001B[0mmorph_tagger\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNewsMorphTagger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0memb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m                 \u001B[0mdoc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msegment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msegmenter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\natasha\\morph\\tagger.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, emb, path)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mNewsMorphTagger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMorphTagger\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mNEWS_MORPH\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m         \u001B[0mMorphTagger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\natasha\\morph\\tagger.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, emb, path)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mMorphTagger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSlovnetMorph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m         \u001B[0minfer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSlovnetMorph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mSlovnetMorph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnavec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0memb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\slovnet\\api.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(cls, path, batch_size)\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[0marrays\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m             \u001B[0mwords_vocab\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_vocab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mWORD\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             \u001B[0mshapes_vocab\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_vocab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSHAPE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m             \u001B[0mtags_vocab\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_vocab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mTAG\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\slovnet\\exec\\pack.py\u001B[0m in \u001B[0;36mload_vocab\u001B[1;34m(self, id)\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m         \u001B[0mbytes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 116\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mbytes_vocab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbytes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\slovnet\\exec\\pack.py\u001B[0m in \u001B[0;36mbytes_vocab\u001B[1;34m(bytes)\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[0mcontent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecompress\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbytes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'utf8'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m     \u001B[0mitems\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcontent\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplitlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mVocab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\slovnet\\vocab.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, items)\u001B[0m\n\u001B[0;32m     22\u001B[0m         self.item_ids = {\n\u001B[0;32m     23\u001B[0m             \u001B[0mitem\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mid\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m         }\n\u001B[0;32m     26\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munk_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mUNK\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\slovnet\\vocab.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m         self.item_ids = {\n\u001B[0m\u001B[0;32m     23\u001B[0m             \u001B[0mitem\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mid\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in members_statistics_df.iterrows():\n",
    "    user_id = row.user_id\n",
    "    print(f'\\n\\n\\n============{index + 1} users from {members_statistics_df.index[-1]} succeeded')\n",
    "\n",
    "    general_dialogs_df = pd.read_csv(PATH_TO_SAVE_GENERAL_DF)\n",
    "    user_general_df = general_dialogs_df.loc[general_dialogs_df['from_id'] == user_id]\n",
    "\n",
    "    dialog_id = user_general_df['dialog ID'][user_general_df.index[0]]\n",
    "    dialog_id = str(dialog_id)\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(PATH_TO_DIALOGS_META, dialog_id + '.json'), 'r', encoding='utf-8') as f:\n",
    "            meta_dialog_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f'\\n\\n\\n{dialog_id} not found in {PATH_TO_DIALOGS_META}')\n",
    "        continue\n",
    "\n",
    "    name_dicts = {\n",
    "        \"ru\": [female_ru_names, male_ru_names],\n",
    "        \"en\": [female_ru_ukr_trans_names, male_ru_ukr_trans_names],\n",
    "        \"ua\": [female_ukr_names, male_ukr_names]\n",
    "    }\n",
    "\n",
    "    user_gender = ''\n",
    "    for user in meta_dialog_data['users']:\n",
    "        if user['user_id'] == user_id:\n",
    "            if user['first_name'] is not None:\n",
    "                members_statistics_df.at[index, 'first_name'] = user['first_name']\n",
    "                user_gender = get_user_gender(user['first_name'], name_dicts)\n",
    "\n",
    "            if user['last_name'] is not None:\n",
    "                members_statistics_df.at[index, 'last_name'] = user['last_name']\n",
    "                if user_gender == '':\n",
    "                    user_gender = get_user_gender(user['last_name'], name_dicts)\n",
    "\n",
    "            if user['username'] is not None:\n",
    "                members_statistics_df.at[index, 'username'] = user['username']\n",
    "                if user_gender == '':\n",
    "                    if user['username'][-3:] == 'bot':\n",
    "                        print(f'{user[\"username\"]} is bot and we do not analyse it to get gender')\n",
    "                        continue\n",
    "\n",
    "                    user_gender = get_gender_by_verb(user['user_id'], int(dialog_id), user_general_df)\n",
    "                    print(f'Final gender is {user_gender}')\n",
    "\n",
    "            if user_gender != '':\n",
    "                members_statistics_df.at[index, 'gender'] = user_gender\n",
    "\n",
    "            break\n",
    "\n",
    "cols = ['user_id', 'first_name', \"last_name\", \"username\", \"gender\"]\n",
    "\n",
    "rest_cols = [col for col in members_statistics_df.columns if col not in cols]\n",
    "\n",
    "cols = cols + rest_cols\n",
    "members_statistics_df = members_statistics_df[cols]\n",
    "members_statistics_df.to_csv(USER_PATH_TO_SAVE_GENERAL_DF, index=False)\n",
    "members_statistics_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}