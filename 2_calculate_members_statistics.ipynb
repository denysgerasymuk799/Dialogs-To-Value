{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import gender_guesser.detector as gender\n",
    "from config import PATH_TO_DIALOGS_META, PATH_TO_SAVE_PROCESSED_FILES, PATH_TO_SAVE_GENERAL_DF, \\\n",
    "    USER_PATH_TO_SAVE_GENERAL_DF\n",
    "\n",
    "from utils.text_data_transformation import transform_raw_data\n",
    "from utils.dialog_manipulation import detect_data_language, \\\n",
    "    get_user_step_msgs, if_name_in_dict, add_sleep_bounds, add_subdialogs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "general_dialogs_df = pd.read_csv(PATH_TO_SAVE_GENERAL_DF)\n",
    "with open(os.path.join(PATH_TO_SAVE_PROCESSED_FILES, \"all_dialogs_info.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    dialogs_info = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the path\n",
    "if not os.path.isfile(PATH_TO_SAVE_GENERAL_DF):\n",
    "    logging.error(f'No Dataframe associated with {PATH_TO_SAVE_GENERAL_DF}')\n",
    "else:\n",
    "    df = pd.read_csv(PATH_TO_SAVE_GENERAL_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "def add_sleep_data(data: pd.DataFrame, user_df_path, save=True):\n",
    "    \"\"\"\n",
    "    Add sleep data for each message in a dialog,\n",
    "    and add it in a new column for a particular user,\n",
    "    return new dataframe\n",
    "    \"\"\"\n",
    "    gdf = pd.DataFrame(add_sleep_bounds(data))\n",
    "    if save:\n",
    "        gdf.to_csv(user_df_path, index=False)\n",
    "\n",
    "def add_stats_data(data: pd.DataFrame, df_path, save=True):\n",
    "    \"\"\"\n",
    "    Add mean data for each subdialogs in a dialog,\n",
    "    and add it in a new column for a particular stats,\n",
    "    return new dataframe\n",
    "    \"\"\"\n",
    "    adf = add_subdialogs_stats(data)\n",
    "    data['words_num_mean'] = adf['words_num_mean']\n",
    "    data['reply_time_mean'] = adf['reply_time_mean']\n",
    "    data['message_number_mean'] = adf['message_number_mean']\n",
    "    if save:\n",
    "        data.to_csv(df_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aggregating data\n",
    "add_stats_data(df, PATH_TO_SAVE_GENERAL_DF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User stats\n",
    "add_sleep_data(df, USER_PATH_TO_SAVE_GENERAL_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def get_user_gender(username, name_dicts):\n",
    "    user_gender = ''\n",
    "\n",
    "    first_name = username.strip().split()[0].lower()\n",
    "    print('first_name', first_name)\n",
    "\n",
    "    new_df = pd.DataFrame({'message': [first_name]})\n",
    "    word_lang = detect_data_language(new_df, 'one_word')\n",
    "\n",
    "    for num_df, names_df in enumerate(name_dicts[word_lang]):\n",
    "        if not names_df.loc[names_df['name'].str.lower() == first_name].empty or\\\n",
    "                if_name_in_dict(first_name, names_df):\n",
    "            if num_df == 0:\n",
    "                user_gender = 'female'\n",
    "            else:\n",
    "                user_gender = 'male'\n",
    "            print(f\"{first_name} gender is {user_gender}\\n\")\n",
    "            break\n",
    "\n",
    "    if user_gender == '' and word_lang == 'en':\n",
    "        gender_detector = gender.Detector()\n",
    "        user_gender = gender_detector.get_gender(first_name.capitalize())\n",
    "        if user_gender == 'unknown':\n",
    "            user_gender = ''\n",
    "        print(f\"{first_name} gender is {user_gender}\\n\")\n",
    "\n",
    "    return user_gender\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def get_gender_by_verb(user_id, dialog_id, user_general_df):\n",
    "    lang = detect_data_language('', 'df_loc', PATH_TO_SAVE_GENERAL_DF, dialog_id, user_id)\n",
    "\n",
    "    user_gender = ''\n",
    "    if lang == 'en':\n",
    "        return user_gender\n",
    "\n",
    "    female_gender, male_gender = 0, 0\n",
    "    dialog_step_msgs = get_user_step_msgs(PATH_TO_SAVE_GENERAL_DF, dialog_id, user_id, 100, user_general_df)\n",
    "\n",
    "    for msg in dialog_step_msgs:\n",
    "        msg = transform_raw_data(msg, lang, '', '', 'without_lemma')\n",
    "        for word in msg.split():\n",
    "            word = word.strip()\n",
    "            print(word)\n",
    "            if len(word) <= 2:\n",
    "                continue\n",
    "\n",
    "            if lang == 'ua':\n",
    "                if word[-2:] == 'ла' and morph.tag(word)[0].POS in ('VERB', 'GRND'):\n",
    "                    print('ukr word', word)\n",
    "                    female_gender += 1\n",
    "\n",
    "                elif word[-1] in ('в','к','с')  and morph.tag(word)[0].POS in ('VERB', 'GRND'):\n",
    "                    print('ukr word', word)\n",
    "                    male_gender += 1\n",
    "\n",
    "            elif lang == 'ru':\n",
    "                segmenter = Segmenter()\n",
    "                doc = Doc(word)\n",
    "                emb = NewsEmbedding()\n",
    "                morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "                doc.segment(segmenter)\n",
    "                doc.tag_morph(morph_tagger)\n",
    "\n",
    "                if word[-2:] == 'ла' and doc.tokens[0].pos in ('VERB', 'AUX'):\n",
    "                    print('ru word', word)\n",
    "                    female_gender += 1\n",
    "\n",
    "\n",
    "                elif word[-1] in ('л','к','с') and doc.tokens[0].pos in ('VERB', 'AUX'):\n",
    "                    print('ru word', word)\n",
    "                    male_gender += 1\n",
    "\n",
    "    if male_gender > female_gender:\n",
    "        user_gender = 'male'\n",
    "\n",
    "    elif male_gender < female_gender:\n",
    "        user_gender = 'female'\n",
    "\n",
    "    else:\n",
    "        user_gender = ''\n",
    "\n",
    "    return user_gender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pymorphy2-dicts-uk in d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages (2.4.1.1.1460299261)\n",
      "Requirement already up-to-date: pymorphy2-dicts-ru in d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages (2.4.404381.4453942)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'd:\\python\\envs\\venv_telegram_analysis\\scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'd:\\python\\envs\\venv_telegram_analysis\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pymorphy2-dicts-uk\n",
    "!pip install -U pymorphy2-dicts-ru"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "female_ukr_names = pd.read_csv(os.path.join('dicts', 'female_ukrainian_names.csv'))\n",
    "male_ukr_names = pd.read_csv(os.path.join('dicts', 'male_ukrainian_names.csv'))\n",
    "female_ru_names = pd.read_csv(os.path.join('dicts', 'female_russian_names.csv'))\n",
    "male_ru_names = pd.read_csv(os.path.join('dicts', 'male_russian_names.csv'))\n",
    "\n",
    "female_ru_ukr_trans_names = pd.read_csv(os.path.join('dicts', 'female_ru_ukr_trans_names.csv'))\n",
    "male_ru_ukr_trans_names = pd.read_csv(os.path.join('dicts', 'male_ru_ukr_trans_names.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "members_statistics_df = pd.read_csv(USER_PATH_TO_SAVE_GENERAL_DF)\n",
    "\n",
    "members_statistics_df['first_name'], members_statistics_df['last_name'],\\\n",
    "members_statistics_df['username'], members_statistics_df['gender'] = '', '', '', ''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============1 users from 297 succeeded\n",
      "first_name ivan\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "ivan gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============2 users from 297 succeeded\n",
      "first_name yurii\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "yurii gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============3 users from 297 succeeded\n",
      "first_name vitaliia\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "vitaliia gender is \n",
      "\n",
      "first_name ioffe\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "ioffe gender is \n",
      "\n",
      "вообще\n",
      "технический\n",
      "сейлз\n",
      "представляет\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============4 users from 297 succeeded\n",
      "first_name azim\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "azim gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============5 users from 297 succeeded\n",
      "first_name max.d\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "max.d gender is \n",
      "\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============6 users from 297 succeeded\n",
      "first_name quartermaster\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "quartermaster gender is \n",
      "\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============7 users from 297 succeeded\n",
      "first_name sawyer\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "sawyer gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============8 users from 297 succeeded\n",
      "first_name eugene\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "eugene gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============9 users from 297 succeeded\n",
      "first_name hex\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "hex gender is \n",
      "\n",
      "нашлись\n",
      "книжки\n",
      "ищу\n",
      "Final gender is \n",
      "\n",
      "\n",
      "\n",
      "============10 users from 297 succeeded\n",
      "first_name eugene\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "eugene gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============11 users from 297 succeeded\n",
      "first_name maria\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "maria gender is female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============12 users from 297 succeeded\n",
      "first_name stas\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "stas gender is male\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============13 users from 297 succeeded\n",
      "first_name serhey\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n",
      "serhey gender is \n",
      "\n",
      "first_name shmyg\n",
      "data.index[-1] 0\n",
      "n_msgs_to_analyse 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\my_work\\programming\\telegram-dialogs-analysis\\utils\\dialog_manipulation.py:274: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  if n_row % msgs_step == 0:\n",
      "d:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-54-dd06efc3dc74>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m                 \u001B[0mmembers_statistics_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mat\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'last_name'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0muser\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'last_name'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0muser_gender\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m''\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m                     \u001B[0muser_gender\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_user_gender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'last_name'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname_dicts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0muser\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'username'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-49-68ef4f87154e>\u001B[0m in \u001B[0;36mget_user_gender\u001B[1;34m(username, name_dicts)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0muser_gender\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m''\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mword_lang\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'en'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0mgender_detector\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgender\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDetector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m         \u001B[0muser_gender\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgender_detector\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_gender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfirst_name\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcapitalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0muser_gender\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'unknown'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\gender_guesser\\detector.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, case_sensitive)\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[1;34m\"\"\"Creates a detector parsing given data file\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcase_sensitive\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcase_sensitive\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"data/nam_dict.txt\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_parse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\envs\\venv_telegram_analysis\\lib\\site-packages\\gender_guesser\\detector.py\u001B[0m in \u001B[0;36m_parse\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnames\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"utf-8\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_eat_name_line\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\python\\lib\\codecs.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    712\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    713\u001B[0m         \u001B[1;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 714\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    715\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    716\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\python\\lib\\codecs.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m         \u001B[1;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 645\u001B[1;33m         \u001B[0mline\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    646\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    647\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\python\\lib\\codecs.py\u001B[0m in \u001B[0;36mreadline\u001B[1;34m(self, size, keepends)\u001B[0m\n\u001B[0;32m    556\u001B[0m         \u001B[1;31m# If size is given, we call read() only once\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 558\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreadsize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfirstline\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    559\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m                 \u001B[1;31m# If we're at a \"\\r\" read one extra character (which might\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\python\\lib\\codecs.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, size, chars, firstline)\u001B[0m\n\u001B[0;32m    496\u001B[0m                 \u001B[0mnewdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m                 \u001B[0mnewdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    499\u001B[0m             \u001B[1;31m# decode bytes (those remaining from the last call included)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbytebuffer\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mnewdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in members_statistics_df.iterrows():\n",
    "\n",
    "    user_id = row.user_id\n",
    "    print(f'\\n\\n\\n============{index + 1} users from {members_statistics_df.index[-1]} succeeded')\n",
    "\n",
    "    user_general_df = general_dialogs_df.loc[general_dialogs_df['from_id'] == user_id]\n",
    "\n",
    "    dialog_id = user_general_df['dialog ID'][user_general_df.index[0]]\n",
    "    dialog_id = str(dialog_id)\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(PATH_TO_DIALOGS_META, dialog_id + '.json'), 'r', encoding='utf-8') as f:\n",
    "            meta_dialog_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f'\\n\\n\\n{dialog_id} not found in {PATH_TO_DIALOGS_META}')\n",
    "        continue\n",
    "\n",
    "    name_dicts = {\n",
    "        \"ru\": [female_ru_names, male_ru_names],\n",
    "        \"en\": [female_ru_ukr_trans_names, male_ru_ukr_trans_names],\n",
    "        \"ua\": [female_ukr_names, male_ukr_names]\n",
    "    }\n",
    "\n",
    "    user_gender = ''\n",
    "    for user in meta_dialog_data['users']:\n",
    "        if user['user_id'] == user_id:\n",
    "            if user['first_name'] is not None:\n",
    "                members_statistics_df.at[index, 'first_name'] = user['first_name']\n",
    "                user_gender = get_user_gender(user['first_name'], name_dicts)\n",
    "\n",
    "            if user['last_name'] is not None:\n",
    "                members_statistics_df.at[index, 'last_name'] = user['last_name']\n",
    "                if user_gender == '':\n",
    "                    user_gender = get_user_gender(user['last_name'], name_dicts)\n",
    "\n",
    "            if user['username'] is not None:\n",
    "                members_statistics_df.at[index, 'username'] = user['username']\n",
    "                if user_gender == '':\n",
    "                    if user['username'][-3:] == 'bot':\n",
    "                        print(f'{user[\"username\"]} is bot and we do not analyse it to get gender')\n",
    "                        continue\n",
    "\n",
    "                    user_gender = get_gender_by_verb(user['user_id'], int(dialog_id), user_general_df)\n",
    "                    print(f'Final gender is {user_gender}')\n",
    "\n",
    "            if user_gender != '':\n",
    "                members_statistics_df.at[index, 'gender'] = user_gender\n",
    "\n",
    "            break\n",
    "\n",
    "cols = ['user_id', 'first_name', \"last_name\", \"username\", \"gender\"]\n",
    "\n",
    "rest_cols = [col for col in members_statistics_df.columns if col not in cols]\n",
    "\n",
    "cols = cols + rest_cols\n",
    "members_statistics_df = members_statistics_df[cols]\n",
    "members_statistics_df.to_csv(USER_PATH_TO_SAVE_GENERAL_DF, index=False)\n",
    "members_statistics_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}