{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_transformation import prepare_dialogs, if_in_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas~=0.25.3\n",
      "  Downloading pandas-0.25.3-cp38-cp38-macosx_10_9_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 755 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.17.0\n",
      "  Downloading numpy-1.17.5-cp38-cp38-macosx_10_9_x86_64.whl (15.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.1 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk~=3.4\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: word2number~=1.1 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.1)\n",
      "Collecting num2words~=0.5.10\n",
      "  Using cached num2words-0.5.10-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: pymorphy2~=0.8 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.8)\n",
      "Collecting pip~=20.2.2\n",
      "  Using cached pip-20.2.2-py2.py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tokenize_uk~=0.2.0 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: matplotlib~=3.3.1 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (3.3.1)\n",
      "Collecting scikit-learn~=0.23.2\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 2.9 MB/s eta 0:00:01     |█████▏                          | 1.2 MB 3.3 MB/s eta 0:00:02     |██████████████████▋             | 4.2 MB 4.4 MB/s eta 0:00:01     |██████████████████████████▏     | 5.9 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from pandas~=0.25.3->-r requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from pandas~=0.25.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Collecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2020.7.14.tar.gz (690 kB)\n",
      "\u001b[K     |████████████████████████████████| 690 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from num2words~=0.5.10->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from pymorphy2~=0.8->-r requirements.txt (line 6)) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from pymorphy2~=0.8->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: six in /Users/akurochkin/testenv/lib/python3.8/site-packages (from tokenize_uk~=0.2.0->-r requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from matplotlib~=3.3.1->-r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from matplotlib~=3.3.1->-r requirements.txt (line 9)) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from matplotlib~=3.3.1->-r requirements.txt (line 9)) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from matplotlib~=3.3.1->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/akurochkin/testenv/lib/python3.8/site-packages (from matplotlib~=3.3.1->-r requirements.txt (line 9)) (2020.6.20)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp38-cp38-macosx_10_9_x86_64.whl (28.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.9 MB 4.4 MB/s eta 0:00:01    |████                            | 3.7 MB 1.4 MB/s eta 0:00:19     |██████▋                         | 6.0 MB 1.4 MB/s eta 0:00:17     |████████████████████▉           | 18.8 MB 3.7 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Using legacy setup.py install for nltk, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for regex, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, pandas, click, joblib, regex, tqdm, nltk, num2words, pip, scipy, threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\n",
      "    Running setup.py install for regex ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/akurochkin/testenv/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-install-jilxgfoo/regex/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-install-jilxgfoo/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-record-jp9179wy/install-record.txt --single-version-externally-managed --compile --install-headers /Users/akurochkin/testenv/include/site/python3.8/regex\n",
      "         cwd: /private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-install-jilxgfoo/regex/\n",
      "    Complete output (24 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.9-x86_64-3.8\n",
      "    creating build/lib.macosx-10.9-x86_64-3.8/regex\n",
      "    copying regex_3/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/regex\n",
      "    copying regex_3/regex.py -> build/lib.macosx-10.9-x86_64-3.8/regex\n",
      "    copying regex_3/_regex_core.py -> build/lib.macosx-10.9-x86_64-3.8/regex\n",
      "    copying regex_3/test_regex.py -> build/lib.macosx-10.9-x86_64-3.8/regex\n",
      "    running build_ext\n",
      "    building 'regex._regex' extension\n",
      "    creating build/temp.macosx-10.9-x86_64-3.8\n",
      "    creating build/temp.macosx-10.9-x86_64-3.8/regex_3\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -I/Users/akurochkin/testenv/include -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -c regex_3/_regex.c -o build/temp.macosx-10.9-x86_64-3.8/regex_3/_regex.o\n",
      "    In file included from /usr/local/Cellar/gcc@4.9/4.9.4_1/lib/gcc/4.9/gcc/x86_64-apple-darwin16.7.0/4.9.4/include-fixed/syslimits.h:7:0,\n",
      "                     from /usr/local/Cellar/gcc@4.9/4.9.4_1/lib/gcc/4.9/gcc/x86_64-apple-darwin16.7.0/4.9.4/include-fixed/limits.h:34,\n",
      "                     from /Library/Frameworks/Python.framework/Versions/3.8/include/python3.8/Python.h:11,\n",
      "                     from regex_3/_regex.c:48:\n",
      "    /usr/local/Cellar/gcc@4.9/4.9.4_1/lib/gcc/4.9/gcc/x86_64-apple-darwin16.7.0/4.9.4/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory\n",
      "     #include_next <limits.h>  /* recurse down to the real one */\n",
      "                                                                 ^\n",
      "    compilation terminated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /Users/akurochkin/testenv/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-install-jilxgfoo/regex/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-install-jilxgfoo/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-record-jp9179wy/install-record.txt --single-version-externally-managed --compile --install-headers /Users/akurochkin/testenv/include/site/python3.8/regex Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/Users/akurochkin/testenv/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Desklop/Uk_Stemmer\n",
      "  Cloning https://github.com/Desklop/Uk_Stemmer to /private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-req-build-u78_wvnb\n",
      "Building wheels for collected packages: uk-stemmer\n",
      "  Building wheel for uk-stemmer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for uk-stemmer: filename=uk_stemmer-1.0-py3-none-any.whl size=9498 sha256=21815c007406eb80b2344666d439ff325138f81df816aec6c8ef75625025954a\n",
      "  Stored in directory: /private/var/folders/b3/dv3g0qqj6z13sqw26_2z04140000gp/T/pip-ephem-wheel-cache-e7uvmikz/wheels/40/53/2f/982431dc2aff61a4eb52a030950bbbdef0d9178114373d6c0e\n",
      "Successfully built uk-stemmer\n",
      "Installing collected packages: uk-stemmer\n",
      "Successfully installed uk-stemmer-1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: add this packages to the requirements.txt file\n",
    "\n",
    "# !pip install -U nlpcube\n",
    "# !pip install stop-words\n",
    "# !pip install git+https://github.com/Desklop/Uk_Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: rename this method, calculate is to generic word, name should give you information about method\n",
    "def calculate_df(dialog_data, date_before, date_after, user_id_get_msg, dialog_id, path_to_static):\n",
    "    \"\"\"\n",
    "    :param dialog_data: a pandas dataframe of dialogs\n",
    "    :param date_before: datetime type, from what time start to analyse msgs\n",
    "    :param date_after: datetime type, to what time to analyse msgs\n",
    "    :param user_id_get_msg: a user chat id, who msgs to analyse or \"all\" - for all participants of the dialog\n",
    "    :param dialog_id: str\n",
    "    :return: a sorted df - sorted dict of user_id_get_msg most used words\n",
    "    \"\"\"\n",
    "    DF = {}\n",
    "    file_text = \"\"\n",
    "\n",
    "    for row in dialog_data.index:\n",
    "        if user_id_get_msg != \"all\":\n",
    "            if dialog_data[\"from_id\"][row] != user_id_get_msg:\n",
    "                continue\n",
    "\n",
    "        if if_in_date_range(dialog_data[\"date\"][row][:-6], date_before, date_after) == 'Dialog after date_after':\n",
    "            continue\n",
    "\n",
    "        elif if_in_date_range(dialog_data[\"date\"][row][:-6], date_before, date_after):\n",
    "            if not pd.isnull(dialog_data[\"message\"][row]):\n",
    "                file_text += dialog_data[\"message\"][row] + \" \"\n",
    "                for w in dialog_data[\"message\"][row].split():\n",
    "                    try:\n",
    "                        DF[w] += 1\n",
    "                    except:\n",
    "                        DF[w] = 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    with open(path_to_static + \"{}/1_{}.txt\".format(dialog_id, dialog_id), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(file_text)\n",
    "\n",
    "    DF_sorted = {k: v for k, v in sorted(DF.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    return DF_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) change a dialog_id, which you want to investigate\n",
    "dialog_id = \"1355484549\"\n",
    "\n",
    "# 2) change user_id_get_msg\n",
    "# int type - user chat id, who massages you want to analyse,\n",
    "# you can find it in <dialog_id>.csv\n",
    "# str type \"all\" if you want to analyse msgs of all users of the dialog\n",
    "user_id_get_msg = 511986933\n",
    "dialog_path = \"data/dialogs/\"\n",
    "prep_path = 'data/prepared_dialogs/'\n",
    "\n",
    "# TODO: path_to_static, static what? you should rename this folder with respect to its purpose!\n",
    "path_to_static = \"data/tmp_static/\"\n",
    "\n",
    "# TODO: rename date_before and date_after -> start_date and end_date\n",
    "# 3) change to date range in what you want to analyse messages of user_id_get_msg - from date_before to date_after;\n",
    "# format \"%Y-%m-%d %H:%M:%S\"\n",
    "date_before = datetime.datetime(2020, 7, 9, 0, 0, 0)\n",
    "date_after = datetime.datetime(2020, 8, 10, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add log file path to global var\n",
    "logging.basicConfig(filename='logs/project_logs.log', level=0)\n",
    "logging.info(\"starting logs for tf_idf_dialogs\")\n",
    "\n",
    "# TODO: move instructions in the README file\n",
    "\n",
    "# 0) in console input: import nltk; nltk.download()\n",
    "#\n",
    "# Install (or update) NLP-Cube with:\n",
    "# pip3 install -U nlpcube\n",
    "#\n",
    "# use telegram-data-collection/0_download_dialogs_list.py and 1_download_dialogs_data.py\n",
    "# to get some files to analyse\n",
    "# files SHOULD be in data/dialogs and data/dialogs_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_to_static):\n",
    "    os.mkdir(path_to_static)\n",
    "    \n",
    "if not os.path.exists(path_to_static + dialog_id):\n",
    "    os.mkdir(path_to_static + dialog_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX 146\n",
      "INDEX 149\n",
      "INDEX 150\n",
      "INDEX 151\n",
      "INDEX 154\n",
      "INDEX 155\n",
      "INDEX 156\n",
      "INDEX 157\n",
      "INDEX 158\n",
      "INDEX 161\n",
      "INDEX 162\n",
      "INDEX 163\n",
      "INDEX 164\n",
      "INDEX 165\n",
      "INDEX 166\n",
      "INDEX 169\n",
      "INDEX 170\n",
      "INDEX 173\n",
      "INDEX 174\n",
      "INDEX 175\n",
      "INDEX 178\n",
      "INDEX 179\n",
      "INDEX 180\n",
      "INDEX 181\n",
      "INDEX 182\n",
      "INDEX 185\n",
      "INDEX 186\n",
      "INDEX 187\n",
      "INDEX 188\n",
      "INDEX 189\n",
      "INDEX 192\n",
      "INDEX 193\n",
      "INDEX 194\n",
      "INDEX 195\n",
      "INDEX 196\n",
      "INDEX 199\n",
      "INDEX 200\n",
      "INDEX 201\n",
      "INDEX 202\n",
      "INDEX 203\n",
      "INDEX 206\n",
      "INDEX 207\n",
      "INDEX 209\n",
      "INDEX 210\n",
      "INDEX 211\n",
      "INDEX 212\n",
      "INDEX 217\n",
      "INDEX 218\n",
      "INDEX 226\n",
      "INDEX 227\n",
      "INDEX 228\n",
      "INDEX 231\n",
      "INDEX 232\n",
      "INDEX 233\n",
      "INDEX 234\n",
      "INDEX 235\n",
      "INDEX 238\n",
      "INDEX 239\n",
      "INDEX 240\n",
      "INDEX 241\n",
      "INDEX 242\n",
      "INDEX 243\n",
      "INDEX 246\n",
      "INDEX 247\n",
      "INDEX 248\n",
      "INDEX 249\n",
      "INDEX 250\n",
      "INDEX 253\n",
      "INDEX 254\n",
      "INDEX 255\n",
      "INDEX 256\n",
      "INDEX 257\n",
      "INDEX 258\n",
      "INDEX 261\n",
      "INDEX 262\n",
      "INDEX 263\n",
      "INDEX 264\n",
      "INDEX 265\n",
      "INDEX 268\n",
      "INDEX 269\n",
      "INDEX 270\n",
      "INDEX 271\n",
      "INDEX 272\n",
      "INDEX 273\n",
      "INDEX 279\n",
      "INDEX 280\n",
      "INDEX 281\n",
      "INDEX 284\n",
      "INDEX 285\n",
      "INDEX 286\n",
      "INDEX 287\n",
      "INDEX 288\n",
      "INDEX 291\n",
      "INDEX 292\n",
      "INDEX 293\n",
      "INDEX 294\n",
      "INDEX 295\n",
      "INDEX 298\n",
      "INDEX 299\n",
      "INDEX 300\n",
      "INDEX 301\n",
      "INDEX 302\n",
      "INDEX 303\n",
      "INDEX 306\n",
      "INDEX 307\n",
      "INDEX 309\n",
      "INDEX 310\n",
      "INDEX 311\n",
      "INDEX 314\n",
      "INDEX 315\n",
      "INDEX 316\n",
      "INDEX 317\n",
      "INDEX 318\n",
      "INDEX 319\n",
      "INDEX 322\n",
      "INDEX 323\n",
      "INDEX 324\n",
      "INDEX 325\n",
      "INDEX 328\n",
      "INDEX 329\n",
      "INDEX 330\n",
      "INDEX 331\n",
      "INDEX 332\n",
      "INDEX 333\n",
      "INDEX 334\n",
      "INDEX 335\n",
      "INDEX 336\n",
      "INDEX 337\n",
      "INDEX 338\n",
      "INDEX 339\n",
      "INDEX 340\n",
      "INDEX 341\n",
      "INDEX 342\n",
      "INDEX 343\n",
      "INDEX 344\n",
      "INDEX 347\n",
      "INDEX 348\n",
      "INDEX 349\n",
      "INDEX 350\n",
      "INDEX 351\n",
      "INDEX 352\n",
      "INDEX 355\n",
      "INDEX 356\n",
      "INDEX 357\n",
      "INDEX 358\n",
      "INDEX 359\n",
      "INDEX 362\n",
      "INDEX 363\n",
      "INDEX 364\n",
      "INDEX 365\n",
      "INDEX 366\n",
      "INDEX 367\n",
      "INDEX 370\n",
      "INDEX 371\n",
      "INDEX 376\n",
      "INDEX 377\n",
      "INDEX 378\n",
      "INDEX 381\n",
      "INDEX 382\n",
      "INDEX 383\n",
      "INDEX 384\n",
      "INDEX 385\n",
      "INDEX 388\n",
      "INDEX 389\n",
      "INDEX 390\n",
      "INDEX 391\n",
      "INDEX 392\n",
      "INDEX 395\n",
      "INDEX 396\n",
      "INDEX 397\n",
      "INDEX 398\n",
      "INDEX 399\n",
      "INDEX 402\n",
      "INDEX 403\n",
      "INDEX 404\n",
      "INDEX 405\n",
      "INDEX 406\n",
      "INDEX 407\n",
      "INDEX 408\n",
      "INDEX 409\n",
      "INDEX 410\n",
      "INDEX 411\n",
      "INDEX 412\n",
      "INDEX 413\n",
      "INDEX 414\n",
      "INDEX 415\n",
      "INDEX 416\n",
      "INDEX 417\n",
      "INDEX 418\n",
      "INDEX 419\n",
      "INDEX 420\n",
      "INDEX 421\n",
      "INDEX 422\n",
      "INDEX 425\n",
      "INDEX 426\n",
      "INDEX 427\n",
      "INDEX 428\n",
      "INDEX 429\n",
      "INDEX 430\n",
      "INDEX 431\n",
      "INDEX 432\n",
      "INDEX 433\n",
      "INDEX 434\n",
      "INDEX 435\n",
      "INDEX 436\n",
      "INDEX 437\n",
      "INDEX 438\n",
      "INDEX 439\n",
      "INDEX 440\n",
      "INDEX 441\n",
      "INDEX 443\n",
      "INDEX 444\n",
      "INDEX 445\n",
      "INDEX 446\n",
      "INDEX 447\n",
      "INDEX 448\n",
      "INDEX 449\n",
      "INDEX 450\n",
      "INDEX 451\n",
      "INDEX 452\n",
      "INDEX 453\n",
      "INDEX 454\n",
      "INDEX 455\n",
      "INDEX 456\n",
      "INDEX 457\n",
      "INDEX 458\n",
      "INDEX 459\n",
      "INDEX 460\n",
      "INDEX 461\n",
      "INDEX 462\n",
      "INDEX 463\n",
      "INDEX 464\n",
      "INDEX 465\n",
      "INDEX 466\n",
      "INDEX 467\n",
      "INDEX 468\n",
      "INDEX 469\n",
      "INDEX 472\n",
      "INDEX 473\n",
      "INDEX 474\n",
      "INDEX 475\n",
      "INDEX 476\n",
      "INDEX 477\n",
      "INDEX 480\n",
      "INDEX 481\n",
      "INDEX 483\n",
      "INDEX 484\n",
      "INDEX 485\n",
      "INDEX 486\n",
      "INDEX 487\n",
      "INDEX 488\n",
      "INDEX 489\n",
      "INDEX 490\n",
      "INDEX 491\n",
      "INDEX 492\n",
      "INDEX 495\n",
      "INDEX 496\n",
      "INDEX 497\n",
      "INDEX 498\n",
      "INDEX 499\n",
      "INDEX 500\n",
      "INDEX 503\n",
      "INDEX 504\n",
      "INDEX 505\n",
      "INDEX 506\n",
      "INDEX 507\n",
      "INDEX 510\n",
      "INDEX 511\n",
      "INDEX 515\n",
      "INDEX 520\n",
      "INDEX 521\n",
      "INDEX 522\n",
      "INDEX 523\n",
      "INDEX 524\n",
      "INDEX 525\n",
      "INDEX 526\n",
      "INDEX 527\n",
      "INDEX 528\n",
      "INDEX 529\n",
      "INDEX 530\n",
      "INDEX 531\n",
      "INDEX 532\n",
      "INDEX 533\n",
      "INDEX 534\n",
      "INDEX 535\n",
      "INDEX 536\n",
      "INDEX 537\n",
      "INDEX 538\n",
      "INDEX 539\n",
      "INDEX 540\n",
      "INDEX 541\n",
      "INDEX 544\n",
      "INDEX 545\n",
      "INDEX 546\n",
      "INDEX 547\n",
      "INDEX 548\n",
      "INDEX 551\n",
      "INDEX 552\n",
      "INDEX 553\n",
      "INDEX 554\n",
      "INDEX 555\n",
      "INDEX 558\n",
      "INDEX 559\n",
      "INDEX 560\n",
      "INDEX 561\n",
      "INDEX 562\n",
      "INDEX 563\n",
      "INDEX 564\n",
      "INDEX 567\n",
      "INDEX 568\n",
      "INDEX 569\n",
      "INDEX 570\n",
      "INDEX 571\n",
      "INDEX 572\n",
      "INDEX 573\n",
      "INDEX 574\n",
      "INDEX 575\n",
      "INDEX 576\n",
      "INDEX 577\n",
      "INDEX 578\n",
      "INDEX 579\n",
      "INDEX 580\n",
      "INDEX 581\n",
      "INDEX 582\n",
      "INDEX 583\n",
      "start saving\n"
     ]
    }
   ],
   "source": [
    "# TODO: create a method to detect dialog language\n",
    "\n",
    "# 4) change \"ua\" to a language of your dialog (\"ua\", \"ru\" or \"en\")\n",
    "# if you write \"ua\" or \"ru\" - dialog will be cleaned from stop_words_ua + stop_words_ru + stop_words_en\n",
    "# so do not bother about these languages if you can not write an exactly language of the dialog\n",
    "\n",
    "# TODO: move lang to the variable\n",
    "prepare_dialogs(dialog_id, dialog_path, prep_path, date_before,\n",
    "                date_after, \"ru\", \"words_frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_data = pd.read_csv(prep_path + dialog_id + \".csv\")\n",
    "\n",
    "DF_sorted = calculate_df(dialog_data, date_before, date_after, user_id_get_msg, dialog_id, path_to_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_static + \"{}/words_frequency1_{}.json\".format(dialog_id, dialog_id), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(DF_sorted, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 4) after work of this module look at results in static/<dialog_id> dir\n",
    "# use command under to make a wordcloud, to understand its parameters use - wordcloud_cli --help\n",
    "# wordcloud_cli --text static/<dialog_id>/1_<dialog_id>.txt --mask static/logo_telegram.jpg --imagefile static/my_words_nazar2.png\n",
    "print(DF_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
